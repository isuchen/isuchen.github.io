### 关联规则

关联规则，用来寻找事物与事物之间的关系，分析数据之间的相关性。

#### 主要算法
1. Apriori算法
2. FP-growth算法

#### 基本概念

**Support**
用来表明子集在数据集中频繁的程度

$$
Support = \frac{|{t\in T,X \subseteq t }|}{|T|}
$$

给个例子：

T 中包含以下几种组合：

{A,B,C}
{B,C}
{C,D}
{A,B,C,D}

那么{B,C}的support是 3/4 = 0.75

**Confidence**
用来表明一个数据出现之后，另一个数据出现的概率

$$
conf(X \to Y) = supp(X \cup Y)/supp(X)
$$

给个例子：

{A,B,C}
{B,C}
{C,D}
{A,B,C,D}

$$ 
  conf(B \to C) = 
  supp(B,C) / supp(B) = 0.75/0.75 = 1  
$$

**Lift**
表示含有Y的条件下，同时含有X的概率，与X总体发生的概率之比

$$

lift(X \to Y) = \frac{supp(X \cup Y)}{supp(X)\times supp(Y)}
$$

还是上面那个例子：

$$
lift(B \to C) = 0.75/(0.75*1) = 1
$$

#### Apriori算法
*原理*：如果一个项集是频繁项集，则它的所有子集都是频繁项集；如果一个集合不是频繁项集，则它的所有父集（超集）都不是频繁项集

*算法流程*
```
Input:数据集合D，min_support 
Output:最大频繁k项集
Step：
1. 扫描整个数据集，得到所有出现过的数据，作为候选频繁1项集，k =1,频繁0项集为空集
2. 挖掘频繁k项集
    a）扫描数据集，计算候选频繁k项集的支持度
    b）去除候选频繁k项集中支持度小于min_support,得到频繁k项集，如果s频繁k项集里面的个数为0，算法结束，返回k-1的频繁项集，如果频繁k项集中的个数为1，返回频繁k项集，算法结束
    c）基于频繁k项集，继续生成k+1项集
3. 令k = k+1，转到步骤2

```

例子如下图：

<img src = 'img/apriori.png'>

算法优缺点：

1. 频繁扫描数据集，影响性能
2. 候选集太多，虽然已经筛掉一部分了
3. 数候选集的次数，效率不够高，可以优化

#### FP-growth算法

FP-growth算法采用FP-Tree的数据结构来提取频繁项集，不需要产生候选集，每个事务被映射到FP-tree的一条路径上，不同的事务会有相同的路径，因此重叠的越多，压缩效果越好。

*算法流程*
```
1：先扫描一遍数据集，得到频繁项为1的项目集，定义min_support（项目出现最少次数），删除那些小于min_support的项目，然后将原始数据集中的条目按项目集中降序进行排列。 
2：第二次扫描，创建项头表（从上往下降序），以及FP树。 
3：对于每个项目（可以按照从下往上的顺序）找到其条件模式基（CPB，conditional patten base）,递归调用树结构，删除小于min_support的项。如果最终呈现单一路径的树结构，则直接列举所有组合；非单一路径的则继续调用树结构，直到形成单一路径即可。

```

算法优缺点：
1. 扫描数据集次数减少（只需2次）
2. 需要创建项头表。
